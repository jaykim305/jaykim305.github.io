---
---

@inproceedings{scenehub,
  author={Kim, Jaehong and Jin, Tao and Dasari, Mallesham and Seshan, Srinivasan and Rowe, Anthony},
  booktitle={IEEE Transactions on Visualization and Computer Graphics}, 
  title={SceneHub4D: A Dataset and Evaluation Framework for 6-DoF 4D VR Scenes (To appear)}, 
  year={2026},
  volume={},
  number={},
  pages={},
  keywords={},
  url = {},
  html = {},
  website = {https://scenehub4d.github.io/},
  doi={},
  highlight={Top submission, accepted to IEEE TVCG},
  abbr={IEEE VR},
  selected = {true}
}

@inproceedings{nervast,
  author={Lee, Yunheon and Ye, Juncheol and Kim^, Jaehong and Han^, Dongsu},
  booktitle={IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)}, 
  title={NerVast: Compression-Efficient Scaling of Implicit Neural Video Representations via Scene-based Parameter-sharing (To appear)}, 
  year={2026},
  volume={},
  number={},
  pages={},
  keywords={},
  url = {},
  html = {},
  pdf={nervast-wacv26.pdf},
  doi={},
  abbr={WACV},
  selected = {true}
}

@inproceedings{kim2025reconstruct,
  abbr={ISMAR},
  author={Kim, Jaehong and Seshan, Srinivasan and Rowe, Anthony},
  title = {(Poster) Reconstructing Reality over Time: From Drone Capture to Timelapse Gaussian Splatting},
  year = {2025},
  isbn = {},
  publisher = {},
  address = {},
  url = {https://ieeexplore.ieee.org/document/11236292},
  html = {https://ieeexplore.ieee.org/document/11236292},
  doi={10.1109/ISMAR-Adjunct68609.2025.00299},
  booktitle = {IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)},
  pages={905-906},
  numpages = {},
  keywords={Visualization;Three-dimensional displays;Pipelines;Manuals;Rendering (computer graphics);Image reconstruction;Time-varying systems;Monitoring;Augmented reality;Drones;3D Timelapse;Gaussian Splatting},
  location = {},
  series = {ISMAR '25},
  selected = {true},
  ffvideo={https://youtu.be/2vpA6KhxtjA},
  demo={https://youtu.be/ZfpkKSmcY_4},
  selected={true}
}

@inproceedings{lee2025presto,
  abbr={NetAISys},
  author = {Lee, Jihyuk and Han, Dongsu and Kim, Jaehong},
  title = {Presto: Hybrid CPU-GPU Preprocessing Framework for Video-based AI Inference System},
  year = {2025},
  isbn = {9798400714535},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3711875.3736688},
  html = {https://dl.acm.org/doi/abs/10.1145/3711875.3736688},
  doi = {10.1145/3711875.3736688},
  abstract = {The growing adoption of video-based AI models has created a pressing demand for high throughput, low latency inference systems. However, existing preprocessing frameworks—whether CPU or GPU based—struggle to keep up with the computational burdens of video decoding and data augmentation, resulting in suboptimal GPU utilization and degraded inference system performance.In this paper, we present PRESTO, a high-performance hybrid CPU-GPU preprocessing framework tailored for video-based AI inference systems. Presto integrates a hybrid preprocessing scheduler to dynamically balance CPU and GPU workloads, leverages selective decoding to eliminate unnecessary frame processing, and introduces a custom GPU Memory Manager that enables pipelined preprocessing and efficient GPU memory reuse. Through evaluation on the video captioning task, we show that Presto achieves up to 4.37\texttimes{} higher throughput and 2.72\texttimes{} lower latency compared to the de facto baselines, while reducing cloud costs by up to 75\%.},
  booktitle = {Proceedings of the 23rd Annual International Conference on Mobile Systems, Applications and Services},
  pages = {735–740},
  numpages = {6},
  keywords = {hybrid CPU-GPU preprocessing framework, video based ai model inference, cloud computing},
  location = {Hilton Anaheim, Anaheim, CA, USA},
  series = {MobiSys '25},
  selected = {true}
}


@article{lim2025efficient,
  abbr={IEEE Micro},  
  author={Lim, Jinyeong and Ye, Juncheol and Kim, Jaehong and Lim, Hwijoon and Yeo, Hyunho and Jang, Junhyeok and Jung, Myoungsoo and Han, Dongsu},
  journal={IEEE Micro}, 
  title={Efficient Disaggregated Cloud Storage for Cold Videos with Neural Enhancement}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  url = {https://doi.ieeecomputersociety.org/10.1109/MM.2025.3562625},
  html = {https://doi.ieeecomputersociety.org/10.1109/MM.2025.3562625},
  keywords={Videos;Costs;Cloud computing;Training;Bit rate;Metadata;Superresolution;Reliability;Web sites;Video on demand},
  doi={10.1109/MM.2025.3562625},
  selected = {true}
}

@inproceedings{lim2023neural,
  abbr={HotStorage},
  title={Neural Cloud Storage: Innovative Cloud Storage Solution for Cold Video},
  author = {Lim, Jinyeong and Ye, Juncheol and Kim, Jaehong and Lim, Hwijoon and Yeo, Hyunho and Han, Dongsu},
  booktitle={Proceedings of the 15th ACM Workshop on Hot Topics in Storage and File Systems (To appear)},
  year={2023},
  month={July},
  selected={true},
  isbn = {9798400702242},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3599691.3603401},
  html = {https://doi.org/10.1145/3599691.3603401},
  doi = {10.1145/3599691.3603401},
  abstract = {Cloud storage providers offer different pricing tiers based on the access frequency of stored data. This pricing plan offers cost benefits for videos that are accessed less than once per month. However, the stringent requirement falls short in addressing the large number of "cold" videos stored today. This paper proposes Neural Cloud Storage (NCS), a pioneering approach to address the problem by applying neural enhancement, specifically content-aware super-resolution (SR). According to our preliminary cost-benefit analysis, NCS can further save an annual 14\% total cost of ownership (TCO) compared to the cheapest AWS storage service for cold video. By reducing the cost, it expands the cold video coverage (from 25\% to 38\%) that can benefit from the multi-tiered service. As deep learning and computational resources continue to advance, we believe that neural enhancement will revolutionize the field of cloud storage.},
  booktitle = {Proceedings of the 15th ACM Workshop on Hot Topics in Storage and File Systems},
  pages = {1–7},
  numpages = {7},
  keywords = {content-aware super-resolution, cold video, cloud storage},
  location = {Boston, MA, USA},
  series = {HotStorage '23}
}
  


@inproceedings{lim2023flexpass,
  abbr={EuroSys},
  html={https://dl.acm.org/doi/10.1145/3552326.3587453},
  author = {Lim, Hwijoon and Kim, Jaehong and Cho, Inho and Jang, Keon and Bai, Wei and Han, Dongsu},
  title = {FlexPass: A Case for Flexible Credit-Based Transport for Datacenter Networks},
  year = {2023},
  isbn = {9781450394871},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3552326.3587453},
  doi = {10.1145/3552326.3587453},
  abstract = {Proactive transports explicitly allocate bandwidth to each sender with credits which schedule packet transmission. While promising, existing proactive solutions share a stringent deployment requirement; they assume the perfect control of every link and packet in the network. However, the assumption breaks in practice because new transports are usually deployed gradually over time and legacy traffic always coexists. In this paper, we present FlexPass, a credit-based transport that takes deployment flexibility as a first-class citizen. FlexPass uses a novel combination of network and end-host designs to solve the problem of co-existence and gradual deployment. FlexPass leverages a proactive control loop to send credit-scheduled packets and a complementary reactive control loop to send unscheduled packets to utilize the spare bandwidth. Finally, FlexPass prevents queue buildups of both scheduled and unscheduled packets, and recovers lost packets efficiently. Our evaluation on the testbed shows that FlexPass maintains co-existence with legacy transports (DCTCP), while preserving the high-performance properties of the proactive transport. In large-scale simulations, we show that FlexPass delivers the best incremental benefits during the gradual deployment. We find traffic upgraded to FlexPass benefits from the bounded queue and reduced flow completion time by up to 44% compared to the legacy traffic, while minimizing the side-effect on the legacy flows.},
  booktitle = {Proceedings of the Eighteenth European Conference on Computer Systems},
  pages = {606–622},
  numpages = {17},
  keywords = {congestion control, datacenter networking},
  location = {Rome, Italy},
  series = {EuroSys '23},
  website = {https://ina.kaist.ac.kr/projects/flexpass/},
  selected = {true}
}

@inproceedings{kim2022cooptimizing,
  author = {Kim, Jaehong and Lee, Yunheon and Lim, Hwijoon and Jung, Youngmok and Kim, Song Min and Han, Dongsu},
  title = {OutRAN: Co-Optimizing for Flow Completion Time in Radio Access Network},
  year = {2022},
  isbn = {9781450395083},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3555050.3569122},
  doi = {10.1145/3555050.3569122},
  abstract = {Traffic from interactive applications demanding low latency has become dominant in cellular networks. However, existing schedulers of cellular network base stations fall short in delivering low latency when prior information (i.e., dedicated Quality of Service (QoS)) is unavailable; they become service agnostic and perform towards maximizing the radio resource utilization or user fairness. We identify a new opportunity of providing a better latency for those latency-sensitive traffic flows by additionally taking the Flow Completion Time (FCT) into account in downlink scheduling at the base stations. However, the key challenges are 1) it can bring a severe cost in optimization metrics of the existing scheduler and 2) it should work without prior knowledge of the traffic.To this end, we present OutRAN, a practical flow scheduler designed for Radio Access Network that co-optimizes the FCT and optimization objectives of the cellular scheduler. The resulting system does not require prior information. Through simulation and over-the-air evaluation, we demonstrate that OutRAN outperforms the legacy LTE/5G schedulers in FCT, which leads to the reduction in webpage load time of Android phones.},
  booktitle = {Proceedings of the 18th International Conference on Emerging Networking EXperiments and Technologies},
  pages = {369–385},
  numpages = {17},
  keywords = {radio access network, base station, resource scheduling},
  location = {Roma, Italy},
  series = {CoNEXT '22},
  abbr={CoNEXT},
  html={https://doi.org/10.1145/3555050.3569122},
  pdf={outran-conext22.pdf},
  website={https://ina.kaist.ac.kr/projects/outran/},
  highlight={Best Paper Finalist},
  selected={true}
}

@inproceedings{yeo2022sigcomm,
  author = {Yeo, Hyunho and Lim, Hwijoon and Kim, Jaehong and Jung, Youngmok and Ye, Juncheol and Han, Dongsu},
  title = {NeuroScaler: Neural Video Enhancement at Scale},
  year = {2022},
  isbn = {9781450394208},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3544216.3544218},
  doi = {10.1145/3544216.3544218},
  abstract = {High-definition live streaming has experienced tremendous growth. However, the video quality of live video is often limited by the streamer's uplink bandwidth. Recently, neural-enhanced live streaming has shown great promise in enhancing the video quality by running neural super-resolution at the ingest server. Despite its benefit, it is too expensive to be deployed at scale. To overcome the limitation, we present NeuroScaler, a framework that delivers efficient and scalable neural enhancement for live streams. First, to accelerate end-to-end neural enhancement, we propose novel algorithms that significantly reduce the overhead of video super-resolution, encoding, and GPU context switching. Second, to maximize the overall quality gain, we devise a resource scheduler that considers the unique characteristics of the neural-enhancing workload. Our evaluation on a public cloud shows NeuroScaler reduces the overall cost by 22.3\texttimes{} and 3.0--11.1\texttimes{} compared to the latest per-frame and selective neural-enhancing systems, respectively.},
  booktitle = {Proceedings of the ACM SIGCOMM 2022 Conference},
  pages = {795–811},
  numpages = {17},
  keywords = {live streaming, deep neural networks, super-resolution},
  location = {Amsterdam, Netherlands},
  series = {SIGCOMM '22},
  abbr={SIGCOMM},
  html={https://doi.org/10.1145/3544216.3544218},
  pdf={neuroscaler-sigcomm22.pdf},
  website={https://ina.kaist.ac.kr/projects/neuroscaler/},
  selected={true}
}

@inproceedings{kim2020sigcomm,
  author = {Kim*, Jaehong and Jung*, Youngmok and Yeo, Hyunho and Ye, Juncheol and Han, Dongsu},
  title = {Neural-Enhanced Live Streaming: Improving Live Video Ingest via Online Learning},
  year = {2020},
  isbn = {9781450379557},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3387514.3405856},
  doi = {10.1145/3387514.3405856},
  abstract = {Live video accounts for a significant volume of today's Internet video. Despite a large number of efforts to enhance user quality of experience (QoE) both at the ingest and distribution side of live video, the fundamental limitations are that streamer's upstream bandwidth and computational capacity limit the quality of experience of thousands of viewers.To overcome this limitation, we design LiveNAS, a new live video ingest framework that enhances the origin stream's quality by leveraging computation at ingest servers. Our ingest server applies neural super-resolution on the original stream, while imposing minimal overhead on ingest clients. LiveNAS employs online learning to maximize the quality gain and dynamically adjusts the resource use to the real-time quality improvement. LiveNAS delivers high-quality live streams up to 4K resolution, outperforming WebRTC by 1.96 dB on average in Peak-Signal-to-Noise-Ratio on real video streams and network traces, which leads to 12\%-69\% QoE improvement for live stream viewers.},
  booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
  pages = {107–125},
  numpages = {19},
  keywords = {video delivery, deep neural networks, online learning, super-resolution, live streaming},
  location = {Virtual Event, USA},
  series = {SIGCOMM '20},
  abbr={SIGCOMM},
  html={https://doi.org/10.1145/3387514.3405856},
  pdf={livenas-sigcomm20.pdf},
  website={https://ina.kaist.ac.kr/projects/livenas/},
  selected={true}
}


@inproceedings{yeo2018osdi,
  author = {Yeo, Hyunho and Jung, Youngmok and Kim, Jaehong and Shin, Jinwoo and Han, Dongsu},
  title = {Neural Adaptive Content-Aware Internet Video Delivery},
  year = {2018},
  isbn = {9781931971478},
  publisher = {USENIX Association},
  address = {USA},
  abstract = {Internet video streaming has experienced tremendous growth over the last few decades. However, the quality of existing video delivery critically depends on the bandwidth resource. Consequently, user quality of experience (QoE) suffers inevitably when network conditions become unfavorable. We present a new video delivery framework that utilizes client computation and recent advances in deep neural networks (DNNs) to reduce the dependency for delivering high-quality video. The use of DNNs enables us to enhance the video quality independent to the available bandwidth. We design a practical system that addresses several challenges, such as client heterogeneity, interaction with bitrate adaptation, and DNN transfer, in enabling the idea. Our evaluation using 3G and broadband network traces shows the proposed system outperforms the current state of the art, enhancing the average QoE by 43.08\% using the same bandwidth budget or saving 17.13\% of bandwidth while providing the same user QoE.},
  booktitle = {Proceedings of the 13th USENIX Conference on Operating Systems Design and Implementation},
  pages = {645–661},
  numpages = {17},
  location = {Carlsbad, CA, USA},
  series = {OSDI'18},
  abbr={OSDI},
  html={https://www.usenix.org/conference/osdi18/presentation/yeo},
  pdf={osdi18-yeo.pdf},
  website={https://ina.kaist.ac.kr/projects/nas/},
  selected={true}
}



@string{aps = {American Physical Society,}}

@book{einstein1956investigations,
  bibtex_show={true},
  title={Investigations on the Theory of the Brownian Movement},
  author={Einstein, Albert},
  year={1956},
  publisher={Courier Corporation,},
  preview={brownian-motion.gif}
}

@article{einstein1950meaning,
  abbr={AJP},
  bibtex_show={true},
  title={The meaning of relativity},
  author={Einstein, Albert and Taub, AH},
  journal={American Journal of Physics,},
  volume={18},
  number={6},
  pages={403--404},
  year={1950},
  publisher={American Association of Physics Teachers,}
}

@article{PhysRev.47.777,
  abbr={PhysRev},
  title={Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?},
  author={Einstein, A. and Podolsky, B. and Rosen, N.},
  abstract={In a complete theory there is an element corresponding to each element of reality. A sufficient condition for the reality of a physical quantity is the possibility of predicting it with certainty, without disturbing the system. In quantum mechanics in the case of two physical quantities described by non-commuting operators, the knowledge of one precludes the knowledge of the other. Then either (1) the description of reality given by the wave function in quantum mechanics is not complete or (2) these two quantities cannot have simultaneous reality. Consideration of the problem of making predictions concerning a system on the basis of measurements made on another system that had previously interacted with it leads to the result that if (1) is false then (2) is also false. One is thus led to conclude that the description of reality as given by a wave function is not complete.},
  journal={Phys. Rev.,},
  volume={47},
  issue={10},
  pages={777--780},
  numpages={0},
  year={1935},
  month={May},
  publisher=aps,
  doi={10.1103/PhysRev.47.777},
  url={http://link.aps.org/doi/10.1103/PhysRev.47.777},
  html={https://journals.aps.org/pr/abstract/10.1103/PhysRev.47.777},
  pdf={example_pdf.pdf},
  selected={false}
}

@article{einstein1905molekularkinetischen,
  title={{\"U}ber die von der molekularkinetischen Theorie der W{\"a}rme geforderte Bewegung von in ruhenden Fl{\"u}ssigkeiten suspendierten Teilchen},
  author={Einstein, A.},
  journal={Annalen der physik,},
  volume={322},
  number={8},
  pages={549--560},
  year={1905},
  publisher={Wiley Online Library}
}

@article{einstein1905movement,
  abbr={Ann. Phys.},
  title={Un the movement of small particles suspended in statiunary liquids required by the molecular-kinetic theory 0f heat},
  author={Einstein, A.},
  journal={Ann. Phys.,},
  volume={17},
  pages={549--560},
  year={1905}
}

@article{einstein1905electrodynamics,
  title={On the electrodynamics of moving bodies},
  author={Einstein, A.},
  year={1905}
}

@book{przibram1967letters,
  bibtex_show={true},
  title={Letters on wave mechanics},
  author={Einstein, Albert and Schrödinger, Erwin and Planck, Max and Lorentz, Hendrik Antoon and Przibram, Karl},
  year={1967},
  publisher={Vision},
  preview={wave-mechanics.gif}
}
